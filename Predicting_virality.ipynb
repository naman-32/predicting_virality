{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting_virality.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP5de34kgvtDvhK9qVQOuvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naman-32/predicting_virality/blob/master/Predicting_virality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JxN_dU-Zlut",
        "colab_type": "text"
      },
      "source": [
        "# Building the dataset \n",
        "\n",
        "\n",
        "1.  from one news website as appears differerntly google search algorithms\n",
        "2.   one topic like world news\n",
        "3.  not very recent as their shares might not have stagnated from proper response\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFRTYAq2ZR0s",
        "colab_type": "code",
        "outputId": "97453d61-25f9-4a98-9869-fdb79ceae9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# SETTING UP NEWSPAPER LIBRARY\n",
        "!sudo apt-get install python3-pip\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 65%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 2,883 kB of archives.\n",
            "After this operation, 8,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.1 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-xdg all 0.25-4ubuntu1 [31.4 kB]\n",
            "Fetched 2,883 kB in 1s (2,399 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEgo2Zw9Zik2",
        "colab_type": "code",
        "outputId": "70c01c2c-8b66-4437-8411-28fa2d9d4041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!sudo apt-get install python-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 66%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTPPEmq-aJYr",
        "colab_type": "code",
        "outputId": "fc9508de-f88f-4d84-8eb3-78f40e5d7f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!sudo apt-get install libxml2-dev libxslt-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 66%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "Note, selecting 'libxslt1-dev' instead of 'libxslt-dev'\n",
            "libxml2-dev is already the newest version (2.9.4+dfsg1-6.1ubuntu1.3).\n",
            "The following NEW packages will be installed:\n",
            "  libxslt1-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 407 kB of archives.\n",
            "After this operation, 2,473 kB of additional disk space will be used.\n",
            "\r0% [Working]\r            \rGet:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxslt1-dev amd64 1.1.29-5ubuntu0.2 [407 kB]\n",
            "\r0% [1 libxslt1-dev 2,533 B/407 kB 1%]\r                                     \r100% [Working]\r              \rFetched 407 kB in 1s (592 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libxslt1-dev:amd64.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 145248 files and directories currently installed.)\n",
            "Preparing to unpack .../libxslt1-dev_1.1.29-5ubuntu0.2_amd64.deb ...\n",
            "Unpacking libxslt1-dev:amd64 (1.1.29-5ubuntu0.2) ...\n",
            "Setting up libxslt1-dev:amd64 (1.1.29-5ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrn7Ou1FabFq",
        "colab_type": "code",
        "outputId": "9786480a-205c-4441-fdba-28ecbf89f4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!sudo apt-get install libjpeg-dev zlib1g-dev libpng-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 65%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "libpng-dev is already the newest version (1.6.34-1ubuntu0.18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joixnundatf2",
        "colab_type": "code",
        "outputId": "08324597-5ec6-4552-d562-920a72617f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   657  100   657    0     0   3532      0 --:--:-- --:--:-- --:--:--  3532\n",
            "Downloading \"brown\"\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "Downloading \"punkt\"\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Downloading \"maxent_treebank_pos_tagger\"\n",
            "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "Downloading \"movie_reviews\"\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Downloading \"wordnet\"\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Downloading \"stopwords\"\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NykPDAPkbI9o",
        "colab_type": "code",
        "outputId": "5a7eb625-9b26-4cd0-b8bd-9f24cc2bf847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!pip3 install newspaper3k"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 2.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 3.3MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 439kB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 48.4MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.3->newspaper3k) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (46.1.3)\n",
            "Building wheels for collected packages: jieba3k, tinysegmenter, feedparser, feedfinder2\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=5f73056688e5a9d249fb0f0fb730807de06678eebf6a7a9e8c2263c4da92b364\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=408ecc450c6fbb4a67d6c0cf84d4857b2aeef44daee31f3ea839e0fa430945fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=62bcd3efab412c64800ba1c5d408e5c4f6d6ab56c4c63444b38277cffa0c5581\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=6350ca273d9b5c2e895614964d0738c062a810ca2000c5607f77639f809d314e\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "Successfully built jieba3k tinysegmenter feedparser feedfinder2\n",
            "Installing collected packages: cssselect, jieba3k, tinysegmenter, feedparser, feedfinder2, requests-file, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HpywmFbd6zY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TESTING NEWSPAPER \n",
        "# import newspaper\n",
        "# newspaper.languages()\n",
        "# from newspaper import Config, Article, Source\n",
        "\n",
        "# config = Config()\n",
        "# config.MAX_TITLE = 300\n",
        "# config.keep_article_html = True\n",
        "# # config.request_timeout = 50\n",
        "# # config.verbose = True\n",
        "\n",
        "\n",
        "# gd_paper = newspaper.build('https://www.theguardian.com/environment/all' , memoize_articles=False)#, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kAHPA3vXut",
        "colab_type": "code",
        "outputId": "5734674c-6902-4d34-e5e1-5339d091d9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# MOUNTING GOOGLE DRIVE FOR I/O\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VNGCmYwyj8p",
        "colab_type": "code",
        "outputId": "23aaf7f9-cd4e-4845-814c-05e1b203ceb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#INSTALLATION SELENIUM\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\r\u001b[K     |▍                               | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 911kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [91.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [844 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,813 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [19.8 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [52.4 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,505 B]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [908 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [66.6 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,205 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [8,286 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [8,158 B]\n",
            "Get:27 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [875 kB]\n",
            "Fetched 7,606 kB in 3s (2,302 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 108 not upgraded.\n",
            "Need to get 77.2 MB of archives.\n",
            "After this operation, 264 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 81.0.4044.122-0ubuntu0.18.04.1 [1,095 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 81.0.4044.122-0ubuntu0.18.04.1 [68.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 81.0.4044.122-0ubuntu0.18.04.1 [3,230 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 81.0.4044.122-0ubuntu0.18.04.1 [4,070 kB]\n",
            "Fetched 77.2 MB in 4s (20.8 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 145393 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_81.0.4044.122-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEm9bQqNaA_3",
        "colab_type": "code",
        "outputId": "b0d02394-0673-4be1-9746-b58b2bad319f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#install dependecy \n",
        "\n",
        "!pip install python-dateutil"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS32nYL97aDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import json\n",
        "# import urllib.request\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "def scrap_fb_share_guardian_comment(url_input):\n",
        "    ''' \n",
        "    Function to scrap facebook share count and guardian comment count for a guardian article return dictionary with keys share and comment\n",
        "    '''\n",
        "\n",
        "\n",
        "    wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "    url = url_input\n",
        "    # url ='https://www.theguardian.com/environment/2020/may/01/not-just-weeds-how-rebel-botanists-are-using-graffiti-to-name-forgotten-flora-aoe'\n",
        "\n",
        "    wd.get(url)\n",
        "    delay = 5 # seconds\n",
        "    data = dict()\n",
        "    time.sleep(4)\n",
        "    try:\n",
        "        WebDriverWait(wd, delay).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='sharecount__value sharecount__value--full']\")))\n",
        "        \n",
        "        elemfent = wd.find_element_by_css_selector(\"div[class='sharecount__value sharecount__value--full']\")\n",
        "        data['share'] = elemfent.text\n",
        "        # print(elemfent.text)\n",
        "    except TimeoutException:\n",
        "        print(\"Couldn't load share\")\n",
        "        # 0 for denoting error condition or no share\n",
        "        data['share'] = 0\n",
        "       \n",
        "    try:      \n",
        "        WebDriverWait(wd, delay).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"span[class='commentcount2__value tone-colour js_commentcount_actualvalue']\")))  \n",
        "        elemfent = wd.find_element_by_css_selector(\"span[class='commentcount2__value tone-colour js_commentcount_actualvalue']\")\n",
        "        data['comment'] = elemfent.text\n",
        "        # print(elemfent.text)        \n",
        "    except (TimeoutException,NoSuchElementException) as e:\n",
        "        print(\"Couldn't load comment\")\n",
        "        # 0 for denoting error condition or no comments\n",
        "       \n",
        "        data['comment'] = 0\n",
        "    return data\n",
        "\n",
        "\n",
        "# WebDriverWait(wd, delay)#.until(EC.presence_of_element_located((By.CLASS_NAME, 'sharecount__value sharecount__value--full')))\n",
        "# print(\"Page is ready!\")\n",
        "# get_div = wd.find_element_by_class_name((By.CLASS_NAME, 'sharecount__value--full'))#all_elements = driver.find_elements(By.CLASS_NAME, 'my-css-class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftIKErXPcRAN",
        "colab_type": "code",
        "outputId": "fe621f38-d473-49a4-bf5f-3de4c08fa265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# SETTING SELENIUM AND CHROME DRIVER FOR SCRAPING ON COLLAB\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "\n",
        "# REF:- https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "data = scrap_fb_share_guardian_comment('https://www.theguardian.com/environment/2017/jul/16/groundbreaking-cornwall-geothermal-project-seeks-funds')\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Couldn't load comment\n",
            "{'share': '345', 'comment': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9qMWZERJQd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SETTING SELENIUM AND CHROME DRIVER FOR SCRAPING ON COLLAB\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from selenium.webdriver.common.by import By\n",
        "import time \n",
        "\n",
        "# REF:- https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "\n",
        "\n",
        "# IMPORTING OTHER REQUIREMENTS\n",
        "from newspaper import Config, Article, Source\n",
        "import json\n",
        "import csv\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import math\n",
        "from dateutil import parser\n",
        "\n",
        "'''\n",
        "\n",
        "http://content.guardianapis.com/search?q=occupy+wall+street&from-date=2011-09-01&to-date=2012-02-14&page=2\n",
        "\n",
        "&page-size=3&format=json&show-fields=all&use-date=newspaper-edition&api-key=m....g33gzq\n",
        "\n",
        "# https://content.guardianapis.com/search?section=environment&from-date=2016-01-01&to-date=2020-01-01&page-size=50&page=1&lang=en&api-key=yourapikey&show-fields=all&show-tags=keyword\n",
        "https://content.guardianapis.com/environment?q=environment&from-date=2016-01-01&to-date=2020-01-01&page-size=50&page=1&lang=en&api-key=yourapikey&show-fields=all\n",
        "\n",
        "https://content.guardianapis.com/environment?q=environment&from-date=2016-01-01&to-date=2020-01-01&page-size=50&page=1&lang=en&api-key=yourapikey&show-fields=all\n",
        "'''\n",
        "\n",
        "'''step 1: input query information'''\n",
        "apiUrl='https://content.guardianapis.com/environment?q=environment'#'http://content.guardianapis.com/search?q=occupy+wall+street' # set the query word here\n",
        "apiDate='from-date=2016-01-01&to-date=2020-01-01'#'from-date=2011-09-01&to-date=2011-10-14'           # set the date here\n",
        "apiPage='page=1'   # set the page\n",
        "apiNum=50       # set the number of articles in one page\n",
        "apiPageSize=''.join(['page-size=',str(apiNum)])\n",
        "fields='show-fields=all' #format=json&&use-date=newspaper-edition\n",
        "key='api-key=yourapikey' # input your key here\n",
        "api_lang = 'lang=en'\n",
        "\n",
        "'''step 2: get the number of offset/pages'''\n",
        "link=[apiUrl, apiDate, apiPageSize, apiPage, api_lang,  key , fields]\n",
        "ReqUrl='&'.join(link)\n",
        "print(\"*_____________*\", ReqUrl)\n",
        "jstr = urllib.request.urlopen(ReqUrl).read() # t = jstr.strip('()')\n",
        "ts = json.loads( jstr )\n",
        "number=ts['response']['total'] # the number of queries # query=ts['tokens'] # result=ts['results']\n",
        "print(number)\n",
        "seq=range(math.ceil(number / apiNum)) #math.ceil(-23.11)\n",
        "print(seq)\n",
        "\n",
        "'''step 3: crawl the data and dump into csv'''\n",
        "\n",
        "\n",
        "addressForSavingData= \"/content/gdrive/My Drive/predicting_virality/guardian.csv\"#\"D:/Research/Dropbox/tweets/wapor_assessing online opinion/News coverage of ows/guardian.csv\"\n",
        "file = open(addressForSavingData,'w') # save to csv file\n",
        "count = 1\n",
        "for i in seq:\n",
        "    nums=str(i+1)\n",
        "    apiPages=''.join(['page=', nums]) # I made error here, and print is a good way to test\n",
        "    links= [apiUrl, apiDate, apiPageSize, apiPages,  api_lang, key , fields]\n",
        "    ReqUrls='&'.join(links)\n",
        "    print(\"*_____________*\", ReqUrls)\n",
        "    jstrs = urllib.request.urlopen(ReqUrls).read()\n",
        "    # t = jstrs.strip('()')\n",
        "    tss= json.loads( jstrs )\n",
        "    result = tss['response']['results']\n",
        "    \n",
        "    for ob in result:\n",
        "        # title=ob['webTitle'].encode('utf-8') # body=ob['body']  # body,url,title,date,des_facet,desk_facet,byline\n",
        "        # print(title)\n",
        "        # section=ob[\"sectionName\"].encode('utf-8')\n",
        "        art_url = ob['webUrl']\n",
        "        \n",
        "        # date=ob['fields']['newspaperEditionDate'] # date=ob['webPublicationDate'] # byline=ob['fields']['byline']\n",
        "        ds = ob['fields']['firstPublicationDate'] # or any date sting of differing formats.\n",
        "        date = parser.parse(ds)\n",
        "        day = date.weekday()\n",
        "        \n",
        "        content = ob['fields']['bodyText']\n",
        "        \n",
        "        weekday_is_monday=0         #: Was the article published on a Monday?\n",
        "        weekday_is_tuesday=0          #: Was the article published on a Tuesday?\n",
        "        weekday_is_wednesday=0             #: Was the article published on a Wednesday?\n",
        "        weekday_is_thursday=0                 #: Was the article published on a Thursday?\n",
        "        weekday_is_friday=0                    #: Was the article published on a Friday?\n",
        "        weekday_is_saturday=0                #: Was the article published on a Saturday?\n",
        "        weekday_is_sunday=0                       ##: Was the article published on a Sunday?\n",
        "        is_weekend=0                        #:\n",
        "\n",
        "        if day==0:\n",
        "          weekday_is_monday = 1   \n",
        "            \n",
        "        # : Was the article published on a Monday?\n",
        "        if day==1:\n",
        "          weekday_is_tuesday= 1 \n",
        "\n",
        "        # : Was the article published on a Tuesday?\n",
        "        if day==2:\n",
        "          weekday_is_wednesday= 1      \n",
        "        # : Was the article published on a Wednesday?\n",
        "        if day==3:\n",
        "          weekday_is_thursday= 1      \n",
        "        # : Was the article published on a Thursday?\n",
        "        if day==4:\n",
        "          weekday_is_friday= 1      \n",
        "        # : Was the article published on a Friday?\n",
        "        if day==5:\n",
        "          weekday_is_saturday= 1      \n",
        "        # : Was the article published on a Saturday?\n",
        "        if day==6:\n",
        "          weekday_is_sunday= 1      \n",
        "        # : Was the article published on a Sunday?\n",
        "        if day==5 or day==6:\n",
        "          is_weekend = 1\n",
        "       \n",
        "        \n",
        "        \n",
        "        soup = BeautifulSoup(ob['fields']['headline'])\n",
        "        headline = soup.get_text()\n",
        "\n",
        "        soup = BeautifulSoup(ob['fields']['standfirst'])\n",
        "        standfirst = soup.get_text()\n",
        "\n",
        "        soup = BeautifulSoup(ob['fields']['trailText'])\n",
        "        trailText = soup.get_text()\n",
        "        \n",
        "        first_article = Article(url=art_url)\n",
        "        first_article.download()\n",
        "        first_article.parse()\n",
        "\n",
        "        num_images = len(first_article.images)\n",
        "\n",
        "        num_movies = len(first_article.movies)\n",
        "\n",
        "        summary = first_article.summary\n",
        "\n",
        "        keywords = first_article.keywords\n",
        "\n",
        "        num_words = ob['fields']['wordcount']\n",
        "        \n",
        "        data = scrap_fb_share_guardian_comment(art_url)\n",
        "        share_count   = data['share'] \n",
        "        comment_count = data['comment']\n",
        "\n",
        "\n",
        "        w = csv.writer(file,delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "        w.writerow((art_url,\n",
        "                    content,\n",
        "                    weekday_is_monday,\n",
        "                    weekday_is_tuesday,\n",
        "                    weekday_is_wednesday,\n",
        "                    weekday_is_thursday,\n",
        "                    weekday_is_friday,\n",
        "                    weekday_is_saturday,\n",
        "                    weekday_is_sunday,\n",
        "                    is_weekend,  \n",
        "                    headline,\n",
        "                    standfirst,\n",
        "                    trailText,\n",
        "                    num_images,\n",
        "                    num_movies,\n",
        "                    summary,\n",
        "                    keywords,\n",
        "                    num_words,\n",
        "                    share_count,\n",
        "                    comment_count)) # write it out\n",
        "        print(\".\", end =\"\" )\n",
        "        print(count, end =\"\" )\n",
        "        print(art_url)\n",
        "        count = count + 1\n",
        "    print(\"\\n\\n\")  \n",
        "file.close()\n",
        "pass\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PldSl-oV79Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}